mutex的4个发展


1.初版
2.给新人机会
3.多个新人机会
4.解决饿死老人问题


##初版

####初版的mutex是怎么处理的

```
	这里是英文版信号量的copy
	cas(long *addr, long old, long new)
	{
	/* Executes atomically. */
	if(*addr != old)
	return 0;
	*addr = new;
	return 1;
	}


// CAS操作，当时还没有抽象出atomic包
    func cas(val *int32, old, new int32) bool
    func semacquire(*int32)
    func semrelease(*int32)
    // 互斥锁的结构，包含两个字段
    type Mutex struct {
        key  int32 // 锁是否被持有的标识
        sema int32 // 信号量专用，用以阻塞/唤醒goroutine
    }
    
    // 保证成功在val上增加delta的值
    func xadd(val *int32, delta int32) (new int32) {
        for {
            v := *val
            if cas(val, v, v+delta) {
                return v + delta
            }
        }
        panic("unreached")
    }
    
    // 请求锁
    func (m *Mutex) Lock() {
        if xadd(&m.key, 1) == 1 { //标识加1，如果等于1，成功获取到锁
            return
        }
        semacquire(&m.sema) // 否则阻塞等待
    }
    
    func (m *Mutex) Unlock() {
        if xadd(&m.key, -1) == 0 { // 将标识减去1，如果等于0，则没有其它等待者
            return
        }
        semrelease(&m.sema) // 唤醒其它阻塞的goroutine
    }

```

那么既然要发展就肯定是当前代码不满足我们发展的需求了
出现的问题：因为每次获取到的资源的goroutine不一定在M上运行：此处需了解一下GMP
那么如何解决：减少cpu时间片切换带来的上下文的开销，那么就尽可能的将锁交给正在运行的goroutine，减少上下文的切换（一般M都是放在新起的gouroutine上面）


##给新人机会

为什么要多给新人机会呢？还是和GMP调度相关

初版的 Mutex 实现有一个问题：请求锁的 goroutine 会排队等待获取互斥锁。虽然这貌似很公平，但是从性能上来看，却不是最优的。因为如果我们能够把锁交给正在占用 CPU 时间片的 goroutine 的话，那就不需要做上下文的切换，在高并发的情况下，可能会有更好的性能。

```
通过我查看过了一些源码，结合我自身的理解：

1.在mutex上 不是所有携程都在一直循环的去判断锁是否被持有，只有首次进入循环判断锁是否被持有，然后通过semacquire(&m.sema)将自己休眠，不然一个for循环就够把cpu占满了

2.字段 key：是一个 flag，用来标识这个排外锁是否被某个 goroutine 所持有，如果 key 大于等于 1，说明这个排外锁已经被持有；字段 sema：是个信号量变量，用来控制等待 goroutine 的阻塞休眠和唤醒。在上锁过程中不对这个信号量做操作，只要更底层才会进行相关操作


```
state 是一个复合型的字段，一个字段包含多个意义，这样可以通过尽可能少的内存来实现互斥锁。这个字段的第一位（最小的一位）来表示这个锁是否被持有，第二位代表是否有唤醒的 goroutine，剩余的位数代表的是等待此锁的 goroutine 数。所以，state 这一个字段被分成了三部分，代表三个数据。


##多个新人机会

##解决饿死老人